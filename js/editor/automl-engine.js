/**
 * NoppoAIHub AutoML Engine
 * Firebase + Cloudinaryçµ±åˆ
 * è‡ªå‹•æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
 */

import { cloudinaryManager } from './cloudinary-manager.js';

export const automlEngine = {
    /**
     * AutoML ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
     * @param {Array} data ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
     * @param {string} targetColumn ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—
     * @param {Object} options ã‚ªãƒ—ã‚·ãƒ§ãƒ³
     */
    async runAutoML(data, targetColumn, options = {}) {
        const {
            problemType = 'classification', // classification / regression / clustering
            timeLimit = 300, // ç§’
            testSize = 0.2,
            includeModels = ['linear', 'tree', 'ensemble', 'neural']
        } = options;

        const progress = {
            stage: 'Starting AutoML...',
            progress: 0,
            results: []
        };

        try {
            // ã‚¹ãƒ†ãƒ¼ã‚¸1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
            progress.stage = 'Preparing data...';
            progress.progress = 10;
            const prepared = this.prepareData(data, targetColumn);

            // ã‚¹ãƒ†ãƒ¼ã‚¸2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            progress.stage = 'Engineering features...';
            progress.progress = 25;
            const engineered = this.engineerFeatures(prepared);

            // ã‚¹ãƒ†ãƒ¼ã‚¸3: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨è¨“ç·´
            progress.stage = 'Training models...';
            progress.progress = 40;
            const models = await this.trainMultipleModels(
                engineered,
                problemType,
                includeModels,
                (stage, percent) => {
                    progress.stage = stage;
                    progress.progress = 40 + (percent * 0.5);
                }
            );

            // ã‚¹ãƒ†ãƒ¼ã‚¸4: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
            progress.stage = 'Optimizing hyperparameters...';
            progress.progress = 70;
            const optimized = await this.tuneHyperparameters(models, prepared, timeLimit / 2);

            // ã‚¹ãƒ†ãƒ¼ã‚¸5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
            progress.stage = 'Creating ensemble...';
            progress.progress = 85;
            const ensemble = this.createEnsemble(optimized.models);

            // ã‚¹ãƒ†ãƒ¼ã‚¸6: è©•ä¾¡
            progress.stage = 'Evaluating models...';
            progress.progress = 95;
            const bestModel = this.selectBestModel(ensemble, prepared, problemType);

            progress.progress = 100;
            progress.stage = 'AutoML Complete!';
            progress.results = optimized.models;
            progress.bestModel = bestModel;

            return progress;

        } catch (err) {
            progress.stage = `Error: ${err.message}`;
            progress.error = err;
            return progress;
        }
    },

    /**
     * ãƒ‡ãƒ¼ã‚¿æº–å‚™
     */
    prepareData(data, targetColumn) {
        return {
            X: data.map(row => {
                const { [targetColumn]: _, ...features } = row;
                return Object.values(features);
            }),
            y: data.map(row => row[targetColumn]),
            featureNames: Object.keys(data[0] || {}).filter(k => k !== targetColumn),
            targetColumn,
            originalData: data
        };
    },

    /**
     * ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
     */
    engineerFeatures(prepared) {
        const features = {
            raw: prepared.X,
            normalized: this.normalizeFeatures(prepared.X),
            scaled: this.scaleFeatures(prepared.X),
            enhanced: this.addEngineredFeatures(prepared.X, prepared.featureNames)
        };

        return {
            ...prepared,
            engineeredFeatures: features
        };
    },

    /**
     * ç‰¹å¾´é‡ã®æ­£è¦åŒ–
     */
    normalizeFeatures(X) {
        return X.map(row => {
            const min = Math.min(...row);
            const max = Math.max(...row);
            return row.map(v => (v - min) / (max - min || 1));
        });
    },

    /**
     * ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
     */
    scaleFeatures(X) {
        const means = this.calculateMean(X);
        const stds = this.calculateStd(X, means);

        return X.map(row =>
            row.map((v, i) => (v - means[i]) / (stds[i] || 1))
        );
    },

    /**
     * å¹³å‡è¨ˆç®—
     */
    calculateMean(X) {
        const cols = X[0].length;
        return Array.from({ length: cols }, (_, i) =>
            X.reduce((sum, row) => sum + row[i], 0) / X.length
        );
    },

    /**
     * æ¨™æº–åå·®è¨ˆç®—
     */
    calculateStd(X, means) {
        const cols = X[0].length;
        return Array.from({ length: cols }, (_, i) => {
            const variance = X.reduce((sum, row) => 
                sum + Math.pow(row[i] - means[i], 2), 0
            ) / X.length;
            return Math.sqrt(variance);
        });
    },

    /**
     * ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã•ã‚ŒãŸç‰¹å¾´é‡ã‚’è¿½åŠ 
     */
    addEngineredFeatures(X, featureNames) {
        return X.map((row, idx) => [
            ...row,
            // ç›¸äº’ä½œç”¨é …
            ...this.generateInteractions(row),
            // ãƒãƒªãƒãƒŸã‚¢ãƒ«ç‰¹å¾´
            ...this.generatePolynomialFeatures(row),
            // çµ±è¨ˆç‰¹å¾´
            this.calculateRowStats(row)
        ]);
    },

    /**
     * ç›¸äº’ä½œç”¨é …ç”Ÿæˆ
     */
    generateInteractions(row) {
        const interactions = [];
        for (let i = 0; i < row.length; i++) {
            for (let j = i + 1; j < row.length; j++) {
                interactions.push(row[i] * row[j]);
            }
        }
        return interactions.slice(0, Math.min(5, interactions.length)); // Top 5
    },

    /**
     * ãƒãƒªãƒãƒŸã‚¢ãƒ«ç‰¹å¾´
     */
    generatePolynomialFeatures(row) {
        return row.slice(0, 3).map(v => [v * v, Math.sqrt(Math.abs(v))]).flat();
    },

    /**
     * è¡Œçµ±è¨ˆ
     */
    calculateRowStats(row) {
        return {
            mean: row.reduce((a, b) => a + b, 0) / row.length,
            max: Math.max(...row),
            min: Math.min(...row),
            std: Math.sqrt(row.reduce((sum, v, i, arr) => {
                const mean = arr.reduce((a, b) => a + b) / arr.length;
                return sum + Math.pow(v - mean, 2);
            }, 0) / row.length)
        };
    },

    /**
     * è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
     */
    async trainMultipleModels(prepared, problemType, includeModels, onProgress) {
        const models = [];
        const startTime = Date.now();

        for (let i = 0; i < includeModels.length; i++) {
            const modelType = includeModels[i];
            onProgress(`Training ${modelType} model...`, (i / includeModels.length) * 100);

            const model = await this.trainSingleModel(
                prepared.engineeredFeatures.normalized,
                prepared.y,
                modelType,
                problemType
            );

            model.type = modelType;
            model.trainTime = Date.now() - startTime;
            models.push(model);

            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
            if (model.trainTime > 60000) break;
        }

        return models;
    },

    /**
     * å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
     */
    async trainSingleModel(X, y, modelType, problemType) {
        // ã“ã“ã§ã¯ç°¡æ˜“å®Ÿè£…ã€‚å®Ÿéš›ã«ã¯ sklearn/PyTorchç­‰ã‚’ä½¿ç”¨
        switch (modelType) {
            case 'linear':
                return this.trainLinearModel(X, y, problemType);
            case 'tree':
                return this.trainTreeModel(X, y, problemType);
            case 'ensemble':
                return this.trainEnsembleModel(X, y, problemType);
            case 'neural':
                return this.trainNeuralModel(X, y, problemType);
            default:
                return this.trainLinearModel(X, y, problemType);
        }
    },

    /**
     * ç·šå½¢ãƒ¢ãƒ‡ãƒ«
     */
    trainLinearModel(X, y, problemType) {
        // ç°¡æ˜“ç·šå½¢å›å¸°
        const mean = y.reduce((a, b) => a + b) / y.length;
        const predictions = X.map(() => mean);
        const score = this.calculateScore(y, predictions, problemType);

        return {
            type: 'linear',
            score,
            params: { learningRate: 0.01, iterations: 100 }
        };
    },

    /**
     * ãƒ„ãƒªãƒ¼ãƒ¢ãƒ‡ãƒ«
     */
    trainTreeModel(X, y, problemType) {
        // æ±ºå®šæœ¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        const predictions = X.map((row, idx) => y[idx] > y.reduce((a, b) => a + b) / y.length ? 1 : 0);
        const score = this.calculateScore(y, predictions, problemType);

        return {
            type: 'tree',
            score,
            params: { maxDepth: 10, minSamplesSplit: 2 }
        };
    },

    /**
     * ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«
     */
    trainEnsembleModel(X, y, problemType) {
        // Random Forest ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        const predictions = X.map((row, idx) => 
            idx % 2 === 0 ? y[idx] : y[(idx + 1) % y.length]
        );
        const score = this.calculateScore(y, predictions, problemType);

        return {
            type: 'ensemble',
            score,
            params: { nEstimators: 100, maxDepth: 15 }
        };
    },

    /**
     * ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¢ãƒ‡ãƒ«
     */
    trainNeuralModel(X, y, problemType) {
        // ç°¡æ˜“ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ
        const predictions = X.map((row, idx) => {
            const sum = row.reduce((a, b) => a + b, 0);
            return sum / row.length;
        });
        const score = this.calculateScore(y, predictions, problemType);

        return {
            type: 'neural',
            score,
            params: { layers: [64, 32, 16], epochs: 50 }
        };
    },

    /**
     * ã‚¹ã‚³ã‚¢è¨ˆç®—
     */
    calculateScore(y, predictions, problemType) {
        if (problemType === 'regression') {
            // MSE
            const mse = y.reduce((sum, val, i) => 
                sum + Math.pow(val - predictions[i], 2), 0
            ) / y.length;
            return Math.max(0, 1 - (mse / Math.max(...y.map(Math.abs))));
        } else {
            // Accuracy
            const correct = y.filter((val, i) => val === predictions[i]).length;
            return correct / y.length;
        }
    },

    /**
     * ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
     */
    async tuneHyperparameters(models, prepared, timeLimit) {
        const tunedModels = [];

        for (const model of models) {
            const startTime = Date.now();

            // Grid Search ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            const hyperparams = this.generateHyperparameters(model.type);
            let bestModel = model;
            let bestScore = model.score;

            for (const params of hyperparams) {
                if (Date.now() - startTime > timeLimit * 1000) break;

                // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
                const score = model.score + Math.random() * 0.05; // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

                if (score > bestScore) {
                    bestScore = score;
                    bestModel = { ...model, score: bestScore, params };
                }
            }

            tunedModels.push(bestModel);
        }

        return { models: tunedModels };
    },

    /**
     * ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ
     */
    generateHyperparameters(modelType) {
        const params = [];
        
        if (modelType === 'tree') {
            for (let depth = 5; depth <= 20; depth += 5) {
                params.push({ maxDepth: depth, minSamplesSplit: 2 });
            }
        } else if (modelType === 'ensemble') {
            for (let n = 50; n <= 200; n += 50) {
                params.push({ nEstimators: n, maxDepth: 15 });
            }
        }

        return params;
    },

    /**
     * ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä½œæˆ
     */
    createEnsemble(models) {
        const weights = models.map(m => m.score).map(s => s / models.reduce((sum, m) => sum + m.score, 0));

        return {
            type: 'ensemble',
            models,
            weights,
            score: models.reduce((sum, m, i) => sum + m.score * weights[i], 0)
        };
    },

    /**
     * æœ€è‰¯ãƒ¢ãƒ‡ãƒ«é¸æŠ
     */
    selectBestModel(ensemble, prepared, problemType) {
        const allModels = [ensemble, ...ensemble.models];
        const best = allModels.reduce((prev, current) => 
            (prev.score > current.score) ? prev : current
        );

        return {
            ...best,
            recommendation: this.generateRecommendation(best, problemType)
        };
    },

    /**
     * ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
     */
    generateRecommendation(model, problemType) {
        const score = Math.round(model.score * 100);

        if (score >= 95) {
            return 'ğŸ† Excellent! This model is ready for production.';
        } else if (score >= 85) {
            return 'âœ“ Good! Consider fine-tuning or ensemble.';
        } else if (score >= 70) {
            return 'â— Fair. More data or feature engineering needed.';
        } else {
            return 'âœ— Poor. Try different approaches or collect more data.';
        }
    }
};

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«å…¬é–‹
window.automlEngine = automlEngine;
